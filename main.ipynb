{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcardcli.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990</td>\n",
       "      <td>48233</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617</td>\n",
       "      <td>5670</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188948</td>\n",
       "      <td>192815</td>\n",
       "      <td>208365</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1683</td>\n",
       "      <td>1828</td>\n",
       "      <td>3502</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3565</td>\n",
       "      <td>3356</td>\n",
       "      <td>2758</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1645</td>\n",
       "      <td>78379</td>\n",
       "      <td>76304</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47929</td>\n",
       "      <td>48905</td>\n",
       "      <td>49764</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID    LIMIT_BAL SEX EDUCATION  ... PAY_AMT5 PAY_AMT6 default payment next month\n",
       "0         20000   2         2  ...        0        0                          1\n",
       "1        120000   2         2  ...        0     2000                          1\n",
       "2         90000   2         2  ...     1000     5000                          0\n",
       "3         50000   2         2  ...     1069     1000                          0\n",
       "4         50000   1         2  ...      689      679                          0\n",
       "...         ...  ..       ...  ...      ...      ...                        ...\n",
       "29995    220000   1         3  ...     5000     1000                          0\n",
       "29996    150000   1         3  ...        0        0                          0\n",
       "29997     30000   1         2  ...     2000     3100                          1\n",
       "29998     80000   1         3  ...    52964     1804                          1\n",
       "29999     50000   1         2  ...     1000     1000                          1\n",
       "\n",
       "[30000 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.columns.name = \"ID\"\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',\n",
       "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default payment next month'],\n",
       "      dtype='object', name='ID')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['default payment next month'])\n",
    "y = df['default payment next month']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# para usar LSTM se ajusta:\n",
    "num_features = X_train.shape[1]\n",
    "T = None \n",
    "\n",
    "for i in range(1, num_features + 1):\n",
    "    if num_features % i == 0:\n",
    "        T = i\n",
    "        break\n",
    "\n",
    "F = num_features // T\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], T, F)\n",
    "X_test = X_test.reshape(X_test.shape[0], T, F)\n",
    "# fin ajuste\n",
    "\n",
    "# para sequential\n",
    "# X_train = X_train.reshape(X_train.shape[0], 10, -1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 10, -1)\n",
    "\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ]) # 82.15\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(256, activation='leaky_relu', input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(128, activation='leaky_relu'),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(64, activation='leaky_relu'),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(32, activation='leaky_relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ]) # 82.22 con relu, \n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ]) # 81.88\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ]) # 81.88\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='tanh', input_shape=(X_train.shape[1],)),  # Using tanh\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(64, activation='tanh'),  # Using tanh\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(32, activation='tanh'),  # Using tanh\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ]) # 82.15\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 0.4918 - accuracy: 0.8033 - val_loss: 0.4447 - val_accuracy: 0.8125\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4498 - accuracy: 0.8113 - val_loss: 0.4374 - val_accuracy: 0.8157\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4474 - accuracy: 0.8127 - val_loss: 0.4394 - val_accuracy: 0.8127\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4456 - accuracy: 0.8138 - val_loss: 0.4366 - val_accuracy: 0.8148\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4436 - accuracy: 0.8125 - val_loss: 0.4378 - val_accuracy: 0.8158\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4435 - accuracy: 0.8137 - val_loss: 0.4353 - val_accuracy: 0.8150\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4417 - accuracy: 0.8159 - val_loss: 0.4352 - val_accuracy: 0.8138\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4422 - accuracy: 0.8142 - val_loss: 0.4366 - val_accuracy: 0.8097\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4411 - accuracy: 0.8144 - val_loss: 0.4357 - val_accuracy: 0.8128\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4393 - accuracy: 0.8164 - val_loss: 0.4349 - val_accuracy: 0.8107\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4384 - accuracy: 0.8156 - val_loss: 0.4346 - val_accuracy: 0.8148\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4377 - accuracy: 0.8146 - val_loss: 0.4348 - val_accuracy: 0.8148\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4382 - accuracy: 0.8158 - val_loss: 0.4347 - val_accuracy: 0.8132\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4371 - accuracy: 0.8160 - val_loss: 0.4324 - val_accuracy: 0.8168\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4386 - accuracy: 0.8147 - val_loss: 0.4334 - val_accuracy: 0.8155\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4375 - accuracy: 0.8147 - val_loss: 0.4332 - val_accuracy: 0.8153\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4381 - accuracy: 0.8144 - val_loss: 0.4313 - val_accuracy: 0.8175\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4377 - accuracy: 0.8163 - val_loss: 0.4348 - val_accuracy: 0.8165\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4375 - accuracy: 0.8163 - val_loss: 0.4341 - val_accuracy: 0.8162\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4365 - accuracy: 0.8160 - val_loss: 0.4325 - val_accuracy: 0.8170\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4356 - accuracy: 0.8176 - val_loss: 0.4322 - val_accuracy: 0.8163\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4366 - accuracy: 0.8170 - val_loss: 0.4318 - val_accuracy: 0.8180\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4368 - accuracy: 0.8177 - val_loss: 0.4350 - val_accuracy: 0.8165\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4328 - accuracy: 0.8173 - val_loss: 0.4333 - val_accuracy: 0.8165\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4339 - accuracy: 0.8185 - val_loss: 0.4340 - val_accuracy: 0.8173\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4336 - accuracy: 0.8198 - val_loss: 0.4349 - val_accuracy: 0.8138\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4347 - accuracy: 0.8192 - val_loss: 0.4329 - val_accuracy: 0.8178\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4314 - accuracy: 0.8184 - val_loss: 0.4337 - val_accuracy: 0.8167\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4342 - accuracy: 0.8156 - val_loss: 0.4341 - val_accuracy: 0.8162\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4323 - accuracy: 0.8186 - val_loss: 0.4333 - val_accuracy: 0.8165\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4341 - accuracy: 0.8182 - val_loss: 0.4322 - val_accuracy: 0.8178\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4323 - accuracy: 0.8177 - val_loss: 0.4328 - val_accuracy: 0.8167\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4314 - accuracy: 0.8187 - val_loss: 0.4332 - val_accuracy: 0.8168\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.4322 - accuracy: 0.8165 - val_loss: 0.4337 - val_accuracy: 0.8153\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4304 - accuracy: 0.8188 - val_loss: 0.4329 - val_accuracy: 0.8152\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4313 - accuracy: 0.8193 - val_loss: 0.4330 - val_accuracy: 0.8157\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4310 - accuracy: 0.8184 - val_loss: 0.4332 - val_accuracy: 0.8160\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4305 - accuracy: 0.8180 - val_loss: 0.4328 - val_accuracy: 0.8195\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4300 - accuracy: 0.8190 - val_loss: 0.4329 - val_accuracy: 0.8158\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4331 - accuracy: 0.8182 - val_loss: 0.4358 - val_accuracy: 0.8128\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4309 - accuracy: 0.8182 - val_loss: 0.4335 - val_accuracy: 0.8150\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4311 - accuracy: 0.8201 - val_loss: 0.4319 - val_accuracy: 0.8192\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4311 - accuracy: 0.8179 - val_loss: 0.4323 - val_accuracy: 0.8178\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4315 - accuracy: 0.8175 - val_loss: 0.4330 - val_accuracy: 0.8157\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4318 - accuracy: 0.8170 - val_loss: 0.4316 - val_accuracy: 0.8183\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4289 - accuracy: 0.8194 - val_loss: 0.4340 - val_accuracy: 0.8185\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4298 - accuracy: 0.8190 - val_loss: 0.4319 - val_accuracy: 0.8190\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4287 - accuracy: 0.8207 - val_loss: 0.4334 - val_accuracy: 0.8172\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4280 - accuracy: 0.8192 - val_loss: 0.4321 - val_accuracy: 0.8158\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4309 - accuracy: 0.8171 - val_loss: 0.4328 - val_accuracy: 0.8155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ac83566550>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2, input_shape=(T, F)),\n",
    "    tf.keras.layers.LSTM(64, dropout=0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8155\n",
      "Test Loss: [0.43280288577079773, 0.815500020980835]\n",
      "188/188 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "\n",
    "# prediccion usando modelo\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1660404 ],\n",
       "       [0.07815943],\n",
       "       [0.12524506],\n",
       "       ...,\n",
       "       [0.1835067 ],\n",
       "       [0.16528858],\n",
       "       [0.10389739]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.55%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "element_list = [item[0] for item in predictions]\n",
    "\n",
    "binary_predictions = np.round(element_list)\n",
    "\n",
    "accuracy = np.mean(binary_predictions == y_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
